{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_adam_vs_tf_adam",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "Zo-Yk6LFGfSf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "W7gMbs70GxA7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import *\n",
        "from tensorflow.python.keras.optimizers import *\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
        "    for i in range(2, 5):\n",
        "        model.add(Conv2D(filters=64*i, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        model.add(Conv2D(filters=64*i, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        model.add(MaxPooling2D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='linear'))\n",
        "    model.add(Softmax())\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "976MmjAYO9LF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiment 1: `tf.keras.optimizers.Adam`\n",
        "\n",
        "**Use TPU runtime for the next 2 experiments**\n",
        "\n",
        "- Erratic validation loss\n",
        "- Lowest validation loss reached after 17 epochs (0.3026)\n",
        "- Fast epochs (3 seconds)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pWEYmd_hIWg8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1337)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(1337)\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    create_model(),\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "model.compile(\n",
        "    optimizer=Adam(lr=1e-3),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=1024,\n",
        "          epochs=25,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J-W85wJaPLKh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiment 2: `tf.train.AdamOptimizer`\n",
        "\n",
        "- Monotonically decreasing validation loss\n",
        "- Lowest validation loss reached after 9 epochs (0.2082)\n",
        "- Slower epochs (7 seconds)"
      ]
    },
    {
      "metadata": {
        "id": "YS5yWkj0PP5U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1337)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(1337)\n",
        "\n",
        "import os\n",
        "model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    create_model(),\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "model.compile(\n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=1e-3),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=1024,\n",
        "          epochs=25,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VoaWARDQWx4F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiment 3: `tf.keras.optimizers.Adam` on GPU\n",
        "\n",
        "**Switch to GPU runtime for the next 2 experiments**\n",
        "\n",
        "On GPU, both optimizer types show the same results\n",
        "\n",
        "- Monotonically decreasing validation loss\n",
        "- Lowest validation loss reached after 10 epochs (0.2073)\n",
        "- Epochs slower than TPU (since I'm using a K80 on Colab) (37 seconds)\n",
        "- On a V100 I noticed quite a big speed difference as well for the two different optimizer implementations (where `tf.keras.optimizers.Adam` was faster). On a K80 it doesn't seem to matter much"
      ]
    },
    {
      "metadata": {
        "id": "n_sG464CW2H8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1337)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(1337)\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "model = create_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(lr=1e-3),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=1024,\n",
        "          epochs=25,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VjIaj68VXDBr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiment 4: `tf.train.AdamOptimizer` on GPU\n",
        "\n",
        "- Monotonically decreasing validation loss\n",
        "- Lowest validation loss reached after 8 epochs (0.2152)\n",
        "- Epochs slower than TPU (since I'm using a K80 on Colab) (38 seconds)"
      ]
    },
    {
      "metadata": {
        "id": "m65VY6tLW_ij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(1337)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(1337)\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "model = create_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=1e-3),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=1024,\n",
        "          epochs=25,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5BBctbtOZwDr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}